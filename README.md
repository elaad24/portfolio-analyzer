# Portfolio Analyzer

An event-based microservices application for analyzing investment portfolios through file uploads, data parsing, and AI-powered analysis.

## ğŸ—ï¸ Architecture

The system consists of 4 microservices communicating through a message queue:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Node Serviceâ”‚ â”€â”€â”€> â”‚ Message Queueâ”‚ â”€â”€â”€> â”‚Python Workerâ”‚ â”€â”€â”€> â”‚ AI Pipeline  â”‚
â”‚ (HTTP API)  â”‚      â”‚   (Broker)   â”‚      â”‚  (Parser)   â”‚      â”‚ (LangChain)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                     â”‚                     â”‚                     â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                        â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
                        â”‚  Docker   â”‚
                        â”‚  Volume   â”‚
                        â”‚ (Storage) â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

1. **File Upload** â†’ User uploads portfolio files (CSV/XLSX) via REST API
2. **Storage** â†’ Files stored in Docker volume with unique file IDs
3. **Message Queue** â†’ Node service publishes file IDs to message broker
4. **Python Worker** â†’ Consumes messages, parses files, validates data
5. **AI Pipeline** â†’ Processes parsed data using LangChain for analysis
6. **Results** â†’ Analyzed data stored and accessible via API

## ğŸ“¦ Project Structure

```
portfolio-analyzer/
â”œâ”€â”€ node-service/          # HTTP server (TypeScript + Bun)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ routes/       # API endpoints
â”‚   â”‚   â”œâ”€â”€ utils/        # Validation utilities
â”‚   â”‚   â”œâ”€â”€ types/        # TypeScript definitions
â”‚   â”‚   â””â”€â”€ index.ts      # Entry point
â”‚   â””â”€â”€ tests/            # Test suite
â”œâ”€â”€ python-worker/         # File parser service (Python)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ parsers/      # Portfolio parser
â”‚   â”‚   â”œâ”€â”€ ai_pipeline/  # LangChain integration (planned)
â”‚   â”‚   â””â”€â”€ utils/        # Logger utilities
â”‚   â””â”€â”€ requirements.txt
â””â”€â”€ project_architecture.md
```

## ğŸš€ Quick Start

### Prerequisites

- [Bun](https://bun.sh/) (recommended) or Node.js 18+
- Python 3.8+
- Docker (for shared storage and message queue)

### Installation

1. **Clone the repository**

   ```bash
   git clone <repository-url>
   cd portfolio-analyzer
   ```

2. **Setup Node Service**

   ```bash
   cd node-service
   bun install
   ```

3. **Setup Python Worker**

   ```bash
   cd python-worker
   pip install -r requirements.txt
   ```

4. **Start Node Service**
   ```bash
   cd node-service
   bun run dev
   ```
   Service runs at `http://localhost:3000`

## ğŸ“‹ Current Implementation Status

### âœ… Node Service (Implemented)

**Status**: Fully functional file upload service

**Features**:

- Multiple file upload (CSV, XLSX)
- File validation (type, size)
- UUID-based file naming
- Comprehensive test suite (35 tests)
- TypeScript with full type safety

**API Endpoints**:

- `POST /api/files/upload` - Upload portfolio files
- `GET /health` - Health check
- `GET /api/files/download/:filename` - Download files (placeholder)
- `GET /api/files/list` - List files (placeholder)

**File Limits**:

- Max file size: 10MB per file
- Max files per request: 10
- Supported formats: `.csv`, `.xlsx`, `.xls`

**Example Request**:

```bash
curl -X POST http://localhost:3000/api/files/upload \
  -F "files=@portfolio.csv" \
  -F "files=@portfolio2.xlsx"
```

**Response**:

```json
{
  "message": "Processed 2 files",
  "successCount": 2,
  "errorCount": 0,
  "uploadedFiles": [
    {
      "originalName": "portfolio.csv",
      "savedName": "uuid-portfolio.csv",
      "size": 1024,
      "mimetype": "text/csv",
      "extension": ".csv",
      "path": "/path/to/uploads/uuid-portfolio.csv"
    }
  ],
  "timestamp": "2024-01-15T10:30:00.000Z"
}
```

### ğŸ”„ Python Worker (In Progress)

**Status**: Basic structure implemented, not yet integrated

**Features**:

- Portfolio parser using pandas
- Excel/CSV file parsing
- Data validation utilities
- Logger setup

**Pending**:

- Message queue integration
- Docker volume file access
- Integration with Node service

### â³ AI Pipeline (Planned)

**Status**: Not yet implemented

**Planned Features**:

- LangChain integration
- Portfolio analysis algorithms
- Key insights generation
- Result storage

### â³ Message Queue (Planned)

**Status**: Not yet implemented

**Planned**: Local message broker (RabbitMQ/Redis) for service orchestration

## ğŸ› ï¸ Technology Stack

### Node Service

- **Runtime**: Bun (with Node.js compatibility)
- **Language**: TypeScript
- **Framework**: Express.js
- **File Handling**: Multer
- **Testing**: Jest + Supertest

### Python Worker

- **Language**: Python 3.8+
- **Data Processing**: Pandas
- **Excel Support**: openpyxl

### Planned

- **Message Queue**: RabbitMQ or Redis
- **AI Framework**: LangChain
- **Containerization**: Docker Compose

## ğŸ§ª Testing

### Node Service Tests

```bash
cd node-service
bun test                    # Run all tests
bun run test:watch         # Watch mode
bun run test:coverage      # Coverage report
```

**Test Coverage**:

- 24 unit tests (validation utilities)
- 11 integration tests (API endpoints)
- 100% pass rate

## ğŸ“¡ API Reference

### Upload Files

**Endpoint**: `POST /api/files/upload`

**Request**:

- Content-Type: `multipart/form-data`
- Field name: `files` (array)
- Max files: 10
- Max size: 10MB per file

**Response**: `200 OK`

```json
{
  "message": "Processed N files",
  "successCount": number,
  "errorCount": number,
  "uploadedFiles": UploadedFileInfo[],
  "errors": FileUploadError[],
  "timestamp": string
}
```

### Health Check

**Endpoint**: `GET /health`

**Response**: `200 OK`

```json
{
  "status": "OK",
  "uptime": number,
  "timestamp": string
}
```

## ğŸ”’ Security & Validation

- **File Type Validation**: Strict MIME type and extension checking
- **File Size Limits**: 10MB per file maximum
- **Unique File Naming**: UUID-based naming prevents conflicts
- **Input Sanitization**: Proper handling of file metadata
- **Error Handling**: No sensitive information in error messages

## ğŸ“ Planned Endpoints

According to the architecture, the following endpoints are planned:

- `POST /upload` - Upload files (currently `/api/files/upload`)
- `GET /analyzedInfo/:user_uniq_number` - Retrieve analysis results by unique ID

## ğŸ¯ Goals & Roadmap

### Main Goals

- âœ… Express server (Node service)
- ğŸ”„ Python server (Worker)
- â³ LangChain agent (AI Pipeline)
- â³ Message broker
- â³ Docker integration
- â³ Microservices architecture
- âœ… Unit testing (Node service)

### Side Quest Goals

- â³ Swagger documentation
- â³ Rate limiting
- â³ Idempotency
- â³ Redis caching
- â³ Database indexing
- â³ Load balancing

## ğŸ“š Development

### Environment Variables

Create `.env` in `node-service/`:

```env
PORT=3000
NODE_ENV=development
UPLOAD_DIR=./uploads
MAX_FILE_SIZE=10485760  # 10MB
MAX_FILES=10
```

### Running Services

**Node Service**:

```bash
cd node-service
bun run dev    # Development with watch mode
bun run start  # Production
```

**Python Worker**:

```bash
cd python-worker
python src/main.py
```

---

**Built with TypeScript, Python, Express.js, and Bun**
